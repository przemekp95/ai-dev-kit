# ğŸ§  ai-dev-kit

Lokalny zestaw programisty AI â€” gotowy do dziaÅ‚ania offline, z naciskiem na automatyzacjÄ™, prywatnoÅ›Ä‡ i szybki start.

## ğŸ“† Co zawiera

* ğŸ”§ Skrypt `start-all.sh` â€” uruchamia caÅ‚y stack jednym poleceniem  
* ğŸ³ `docker-compose.yml` â€” wielousÅ‚ugowa konfiguracja Dockera  
* ğŸ§  Wsparcie dla lokalnych modeli (w `models/ollama/`)  
* ğŸ” Wsparcie dla embeddingÃ³w (MiniLM, multilingual-e5, SPLADE*)  
* ğŸ—… WebUI (`webui-src/`) â€” graficzny interfejs do interakcji z modelami  
* ğŸ¤– Integracja z Continue (wtyczka do VS Code)  
* ğŸ§ª Kod i testy w `python/`, `php/`, `js/`  
* ğŸ§¹ Lintowanie: ESLint, Prettier, Husky, `lint-staged`  
* ğŸ“š Lokalna baza danych i wektorowa (`data/`)  

## ğŸš€ Szybki start

1. Nadaj prawa wykonania:

```bash
chmod +x start-all.sh
```

2. Uruchom projekt:

```bash
./start-all.sh
```

3. OtwÃ³rz przeglÄ…darkÄ™ i wejdÅº na:

```
http://localhost:3000
```

> â„¹ï¸ Pierwsze uruchomienie moÅ¼e potrwaÄ‡ â€” Docker pobiera obrazy i buduje Å›rodowisko.

---

## ğŸ§  Struktura projektu

```
ai-dev-kit/
â”œâ”€â”€ start-all.sh           # gÅ‚Ã³wny skrypt uruchamiajÄ…cy
â”œâ”€â”€ stop-all.sh            # skrypt zatrzymujÄ…cy
â”œâ”€â”€ docker-compose.yml     # definicje usÅ‚ug Dockera
â”œâ”€â”€ Dockerfile.webui       # Dockerfile do budowy UI
â”œâ”€â”€ data/                  # cache, pliki uÅ¼ytkownika, webui.db
â”œâ”€â”€ embedding-models/      # modele embeddingowe (HF)
â”œâ”€â”€ models/                # modele Ollama (lokalne, ignorowane przez Git)
â”œâ”€â”€ webui-src/             # ÅºrÃ³dÅ‚a WebUI (fork lub submoduÅ‚)
â”œâ”€â”€ python/                # kod i testy w Pythonie
â”œâ”€â”€ php/                   # kod testowy w PHP
â”œâ”€â”€ js/                    # kod JS
â”œâ”€â”€ continue.config.js     # konfiguracja dla Continue (lokalny asystent VS Code)
â”œâ”€â”€ .env, .envrc           # zmienne Å›rodowiskowe
â”œâ”€â”€ .gitattributes, .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§ª Testy i lintowanie

* ObsÅ‚ugiwane przez `lint-staged`, `husky`, `eslint.config.js`, `lint-staged.config.js`  
* Gotowe do dziaÅ‚ania w `python/`, `php/`, `js/`

---

## ğŸ“¦ DuÅ¼e pliki i Git LFS

* Modele (`models/`), cache (`data/`), embeddingi (`embedding-models/`) sÄ… ignorowane przez Git  
* Projekt przygotowany do Git LFS â€” duÅ¼e pliki nie sÄ… commitowane

---

## ğŸ¤– Integracja z Continue (VS Code)

Ten projekt jest w peÅ‚ni kompatybilny z [Continue](https://continue.dev) â€” wtyczkÄ… AI dla VS Code.

1. **Zainstaluj Continue** z Marketplace  
2. **OtwÃ³rz ten folder jako workspace**  
3. Continue automatycznie wykryje lokalny model (`llama3`) i plik `continue.config.js`

DziaÅ‚a offline i lokalnie.

---

## ğŸ”® Co dalej

* [ ] Endpoint `/api/embed` do testowania embeddingÃ³w  
* [ ] `/api/rag` z lokalnym przeszukiwaniem kodu/projektÃ³w  
* [ ] Promptowanie przez Continue (np. â€refactor this functionâ€)  
* [ ] ObsÅ‚uga projektÃ³w kodowych w `/workspace/projekty`

---

## âœ… Gotowe do rozbudowy o GitHub Actions

Repo ma przygotowane lintowanie i moÅ¼e byÄ‡ rozszerzone o peÅ‚ne CI/CD.

---

## ğŸ‘¤ Autor

Projekt tworzony przez [przemekp95](https://github.com/przemekp95) â€” prywatny zestaw deweloperski do lokalnej pracy z AI bez chmury.

---

## ğŸ“„ Licencja

Brak licencji â€” projekt prywatny (moÅ¼e zostaÄ‡ otwarty na Å¼yczenie).
